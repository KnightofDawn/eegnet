{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from six.moves import cPickle as pickle\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "from tensorflow.python.client import timeline\n",
    "\n",
    "print(\"import done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEGNET implementation\n",
    "\n",
    "Part of https://arxiv.org/pdf/1609.03499.pdf that most concerns classification:\n",
    "\"As a last experiment we looked at speech recognition with WaveNets on the TIMIT (Garofolo et al., 1993) dataset. For this task we added a mean-pooling layer after the dilation convolutions that aggregated the activations to coarser frames spanning 10 milliseconds (160 x downsampling). The pooling layer was followed by a few non-causal convolutions. We trained WaveNet with two loss terms, one to predict the next sample and one to classify the frame, the model generalized better than with a single loss and achieved 18.8 PER on the test set, which is to our knowledge the best score obtained from a model trained directly on raw audio on TIMIT.\"\n",
    "\n",
    "Look into: http://static.googleusercontent.com/media/research.google.com/en//pubs/archive/43290.pdf\n",
    "\"Input: This layer extracts 275 ms waveform segments from each of M input microphones. Successive inputs are hopped by 10ms. At the 16kHz sampling rate used in our experiments each segment contains M X 4401 dimensions.\"\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "batch_samples=2400\n",
    "    \n",
    "def read_dataset(folder):\n",
    "    filenames = glob.glob(folder)\n",
    "\n",
    "    reader = tf.TFRecordReader\n",
    "\n",
    "    keys_to_features = {\n",
    "        'data': tf.FixedLenFeature([240000*16], tf.float32),\n",
    "        'label': tf.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    items_to_handlers = {\n",
    "        'data': slim.tfexample_decoder.Tensor('data'),\n",
    "        'label': slim.tfexample_decoder.Tensor('label'),      \n",
    "    }    \n",
    "    decoder = slim.tfexample_decoder.TFExampleDecoder(\n",
    "        keys_to_features, items_to_handlers)\n",
    "\n",
    "    items_to_descriptions = {\n",
    "        'data': '240000 sample points x 16 channels of iEEG.',\n",
    "        'label': 'Label 0 indicates interictal and 1 preictal.', \n",
    "    }\n",
    "\n",
    "    dataset = slim.dataset.Dataset(\n",
    "        data_sources=filenames, \n",
    "        reader=reader, \n",
    "        decoder=decoder, \n",
    "        num_samples=1, \n",
    "        items_to_descriptions=items_to_descriptions)\n",
    "\n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(\n",
    "        dataset, shuffle=True, num_epochs=None, common_queue_capacity=16, common_queue_min=1)\n",
    "\n",
    "    return data_provider.get(['data', 'label'])                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_dataset(data, label):\n",
    "    \n",
    "    \n",
    "    # Batch it up.\n",
    "    return tf.train.shuffle_batch([data, label], \n",
    "                                  batch_size=batch_size, \n",
    "                                  num_threads=1, \n",
    "                                  capacity=2*batch_size, \n",
    "                                  min_after_dequeue=50)\n",
    "\n",
    "shape = data.shape\n",
    "# reshape [batch, samples, channels] into [batch * samples, channels]\n",
    "data = np.reshape(data, (shape[0]*shape[1], shape[2]))\n",
    "# Split 2D array into the desired smaller chuncks\n",
    "data = np.asarray(np.split(data, shape[0]*nr_splits, axis=0))\n",
    "# labels are obtained by repeating original labels nr_splits times\n",
    "labels = np.repeat((np.arange(num_labels) == labels[:,None]).astype(np.float32), nr_splits, axis=0)\n",
    "# normalize and eliminate batches that only contain drop-outs\n",
    "data, labels = clean_normalize_data_labels(data, labels, 0.01)\n",
    "# data has to be 4D for tensorflow (insert an empty dimension)\n",
    "data = data[:,None,:,:]\n",
    "\n",
    "def normalize_array(array):\n",
    "    # Normalize mean=0 and sigma=0.25: axis=0 is along columns, vertical lines.\n",
    "    array -= np.mean(array, axis=0) \n",
    "    array /= 2*np.ptp(array, axis=0)\n",
    "    return array\n",
    "    \n",
    "def clean_normalize_data_labels(data, labels, sigma=0.5):\n",
    "    data_tmp = list()\n",
    "    labels_tmp = list()\n",
    "    for idx, d in enumerate(data):\n",
    "        if (np.count_nonzero(d) < 10) or (np.any(np.std(d, axis=0) < sigma)):\n",
    "            continue\n",
    "        d = normalize_array(d)\n",
    "        data_tmp.append(d)\n",
    "        labels_tmp.append(labels[idx])\n",
    "    return np.asarray(data_tmp), np.asarray(labels_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How many filters to learn for the input.\n",
    "input_channels=16\n",
    "#How many filters to learn for the residual.\n",
    "residual_channels=2*input_channels\n",
    "# size after pooling layer\n",
    "pool_size = 2400\n",
    "# convolution filters width\n",
    "filter_width=3\n",
    "\n",
    "def network(batch_data, reuse=False, is_training=True):\n",
    "    with tf.variable_scope('eegnet_network', reuse=reuse):\n",
    "        with slim.arg_scope([slim.batch_norm], \n",
    "                            is_training=is_training):\n",
    "            with slim.arg_scope([slim.conv2d, slim.fully_connected], \n",
    "                                weights_initializer=slim.xavier_initializer(), \n",
    "                                normalizer_fn=slim.batch_norm):\n",
    "                with tf.variable_scope('input_layer'):\n",
    "                    hidden = slim.conv2d(batch_data, residual_channels, [1, filter_width], stride=1, rate=1, \n",
    "                                         activation_fn=None, scope='conv1')\n",
    "\n",
    "                with tf.variable_scope('hidden'):\n",
    "                    with tf.variable_scope('layer1'):\n",
    "                        layer_input = hidden\n",
    "                        hidden = slim.conv2d(hidden, 2*residual_channels, [1, filter_width], stride=1, rate=2, \n",
    "                                             activation_fn=None, scope='dilconv')\n",
    "                        filtr, gate = tf.split(3, 2, hidden) # split features in half\n",
    "                        hidden = tf.mul(tf.tanh(filtr), tf.sigmoid(gate), name='filterXgate')\n",
    "                        hidden = slim.conv2d(hidden, residual_channels, 1, activation_fn=None, scope='1x1skip')\n",
    "                        skip = hidden # skip conn\n",
    "                        hidden = tf.add(hidden, layer_input) # residual conn\n",
    "                    with tf.variable_scope('layer2'):\n",
    "                        layer_input = hidden\n",
    "                        hidden = slim.conv2d(hidden, 2*residual_channels, [1, filter_width], stride=1, rate=4, \n",
    "                                             activation_fn=None, scope='dilconv')\n",
    "                        filtr, gate = tf.split(3, 2, hidden) # split features in half\n",
    "                        hidden = tf.mul(tf.tanh(filtr), tf.sigmoid(gate), name='filterXgate')\n",
    "                        hidden = slim.conv2d(hidden, residual_channels, 1, activation_fn=None, scope='1x1skip')\n",
    "                        skip = tf.add(skip, hidden) # skip conn\n",
    "                        hidden = tf.add(hidden, layer_input) # residual conn\n",
    "                    with tf.variable_scope('layer3'):\n",
    "                        hidden = slim.conv2d(hidden, 2*residual_channels, [1, filter_width], stride=1, rate=8, \n",
    "                                             activation_fn=None, scope='dilconv')\n",
    "                        filtr, gate = tf.split(3, 2, hidden) # split features in half\n",
    "                        hidden = tf.mul(tf.tanh(filtr), tf.sigmoid(gate), name='filterXgate')\n",
    "                        hidden = slim.conv2d(hidden, residual_channels, 1, activation_fn=None, scope='1x1skip')\n",
    "                        skip = tf.add(skip, hidden) # skip conn\n",
    "\n",
    "                with tf.variable_scope('skip_processing'):\n",
    "                    hidden = tf.nn.relu(skip)\n",
    "                    hidden = slim.avg_pool2d(hidden, [1, batch_samples*2//pool_size], [1, batch_samples//pool_size])\n",
    "                    # 1 x 2400 x residual_channels\n",
    "                    hidden = slim.conv2d(hidden, 32, 1, activation_fn=tf.nn.relu, scope='1x1compress1')\n",
    "                    hidden = slim.conv2d(hidden, 16, [1, 8], stride=4, activation_fn=tf.nn.relu, scope='1x5reduce1')\n",
    "                    # 1 x 600 x 16\n",
    "                    hidden = slim.conv2d(hidden, 8, 1, activation_fn=tf.nn.relu, scope='1x1compress2')\n",
    "                    hidden = slim.conv2d(hidden, 4, [1, 8], stride=4, activation_fn=tf.nn.relu, scope='1x5reduce2')\n",
    "                    # 1 x 150 x 4\n",
    "                    hidden = slim.conv2d(hidden, 2, 1, activation_fn=tf.nn.relu, scope='1x1compress3')\n",
    "                    hidden = slim.conv2d(hidden, 2, [1, 6], stride=3, activation_fn=tf.nn.relu, scope='1x5reduce3')\n",
    "                    # 1 x 75 x 2\n",
    "\n",
    "                with tf.variable_scope('logits'):\n",
    "                    hidden = slim.dropout(hidden, 0.7, is_training=is_training)\n",
    "                    hidden = slim.flatten(hidden)\n",
    "                    logits = slim.fully_connected(hidden, num_labels, activation_fn=None, \n",
    "                                                  normalizer_fn=None, scope='fc1')\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 3840000)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "rank of shape must be at least 4 not: 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f5ec4dd39934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eegnet_handling'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-d73c494bcf06>\u001b[0m in \u001b[0;36mnetwork\u001b[0;34m(batch_data, reuse, is_training)\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'input_layer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     hidden = slim.conv2d(batch_data, residual_channels, [1, filter_width], stride=1, rate=1, \n\u001b[0;32m---> 19\u001b[0;31m                                          activation_fn=None, scope='conv1')\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'hidden'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/ops/arg_scope.pyc\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m   \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_with_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_key_op'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_key_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/layers.pyc\u001b[0m in \u001b[0;36mconvolution2d\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrate\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstride_h\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstride_w\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Only one of rate or stride can be larger than one'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m     \u001b[0mnum_filters_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_rank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     weights_shape = [kernel_h, kernel_w,\n\u001b[1;32m    424\u001b[0m                      num_filters_in, num_outputs]\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/utils.pyc\u001b[0m in \u001b[0;36mlast_dimension\u001b[0;34m(shape, min_rank)\u001b[0m\n\u001b[1;32m    242\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_rank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     raise ValueError('rank of shape must be at least %d not: %d' % (min_rank,\n\u001b[0;32m--> 244\u001b[0;31m                                                                     len(dims)))\n\u001b[0m\u001b[1;32m    245\u001b[0m   \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: rank of shape must be at least 4 not: 3"
     ]
    }
   ],
   "source": [
    "#number of steps after which learning rate is decayed\n",
    "decay_steps=500\n",
    "\n",
    "#Construct computation graph\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    # Input pipeline\n",
    "    train_data, train_labels = read_dataset('./dataset/*.tfr')\n",
    "    train_data, train_labels = preprocess_dataset(train_data, train_labels)\n",
    "    \n",
    "    print(train_data.get_shape())\n",
    "\n",
    "    with tf.name_scope('eegnet_handling'):\n",
    "        logits = network(train_data)\n",
    "        loss = slim.losses.softmax_cross_entropy(logits, train_labels, scope='loss')\n",
    "        tf.scalar_summary('loss', loss)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=1e-3, epsilon=1e-4).minimize(loss, \n",
    "                                                                                      var_list=tf.trainable_variables())\n",
    "        train_probabilities = tf.nn.softmax(logits)\n",
    "        train_predictions = tf.one_hot(tf.argmax(train_probabilities, 1), num_labels, dtype=tf.int32)\n",
    "        train_accuracy = slim.metrics.accuracy(train_predictions, train_labels, 100.0)\n",
    "\n",
    "    init_op = tf.group(tf.initialize_all_variables(), \n",
    "                       tf.initialize_local_variables())\n",
    "    \n",
    "    # Add histograms for trainable variables.\n",
    "    for var in tf.trainable_variables():\n",
    "        tf.histogram_summary(var.op.name, var)\n",
    "        \n",
    "    # Add summaries for activations: NOT WORKING YET. TF ERROR.\n",
    "    #slim.summarize_activations()\n",
    "    \n",
    "    #Merge all summaries and write to a folder\n",
    "    merged_summs = tf.merge_all_summaries()\n",
    "    results_writer = tf.train.SummaryWriter('./results', graph)\n",
    "    \n",
    "    # Add ops to save and restore all the variables.\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    #tracing for timeline\n",
    "    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "    run_metadata = tf.RunMetadata()    \n",
    "    \n",
    "print('computational graph created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch total loss at step 0: 1.053248 | Best: 1.05325\n",
      "Minibatch accuracy: 50.0\n",
      "Predictions | Labels:\n",
      " [[ 0.42321795  0.57678205  1.          0.        ]\n",
      " [ 0.9865399   0.0134601   0.          1.        ]]\n",
      "Last iter time: 1.72764778137\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-12635f117e0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Last iter time:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melapt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mval_accu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mbest_val_accu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_accu\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mval_accu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_accu\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mbest_val_accu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'###-> Validation accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'| Best:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_val_accu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \"\"\"\n\u001b[0;32m--> 559\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_eval_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.pyc\u001b[0m in \u001b[0;36m_eval_using_default_session\u001b[0;34m(tensors, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   3759\u001b[0m                        \u001b[0;34m\"the tensor's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 3761\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_steps = 5001\n",
    "\n",
    "trace_file = open('./tracing/timeline.json', 'w')\n",
    "save_path = './checkpoints/model.ckpt'\n",
    "\n",
    "best_loss = 99.0\n",
    "val_accu = 0.0\n",
    "best_val_accu = 0.0\n",
    "t = 0\n",
    "elapt = 0\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    ttotal = time.time()\n",
    "    init_op.run()\n",
    "    print('Initialized')\n",
    "    for step in range(num_steps):\n",
    "        t = time.time()\n",
    "        _, l, trprob, traccu, summary = session.run(\n",
    "            [optimizer, loss, train_probabilities, train_accuracy, merged_summs], \n",
    "            feed_dict=feed_dict)\n",
    "        results_writer.add_summary(summary, step)\n",
    "        elapt = time.time()\n",
    "        if (step % 13 == 0):\n",
    "            best_loss = l if l < best_loss else best_loss\n",
    "            print('Minibatch total loss at step %d: %f' % (step, l), '| Best:', best_loss)\n",
    "            print('Minibatch accuracy:', traccu)\n",
    "            print('Predictions | Labels:\\n', np.concatenate((trprob[:2], batch_labels[:2]), axis=1))\n",
    "            print('Last iter time:', elapt-t)\n",
    "        if (step % 50 == 0):\n",
    "            val_accu = valid_accuracy.eval()\n",
    "            best_val_accu = val_accu if val_accu > best_val_accu else best_val_accu\n",
    "            print('###-> Validation accuracy:', val_accu, '| Best:', best_val_accu)\n",
    "    ettotal = time.time()\n",
    "    \n",
    "    print('Total time: %f hours' %((ettotal-ttotal)/3600.0))\n",
    "            \n",
    "    # Save tracing into disl\n",
    "    #trace = timeline.Timeline(step_stats=run_metadata.step_stats)\n",
    "    #trace_file.write(trace.generate_chrome_trace_format(show_memory=True))\n",
    "            \n",
    "    # Save the variables to disk.\n",
    "    saver.save(session, save_path)\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "            \n",
    "    results_writer.flush()\n",
    "    results_writer.close()\n",
    "\n",
    "    print('Finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_batch_size = 1\n",
    "\n",
    "def accuracy_notpercent(predictions, labels):\n",
    "  return np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    saver.restore(session, save_path)\n",
    "    print('Model Loaded')\n",
    "    data_split = np.array_split(valid_dataset, valid_dataset.shape[0]//valid_batch_size, axis=0)\n",
    "    labels_split = np.array_split(valid_labels, valid_labels.shape[0]//valid_batch_size, axis=0)\n",
    "    correct_predictions = 0\n",
    "    for idx, batch_data in enumerate(data_split):\n",
    "        correct_predictions += accuracy_notpercent(\n",
    "            train_prediction.eval(feed_dict={tf_train_dataset: batch_data}), \n",
    "            labels_split[idx])\n",
    "        print('accuracy:', (100.0*correct_predictions)/((idx+1)*valid_batch_size))\n",
    "        \n",
    "        \n",
    "    print('Finished validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
